{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO7g8cPepN5HWJyvpS4BxB/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"-Q1NOcOrkiuW","executionInfo":{"status":"ok","timestamp":1733994723463,"user_tz":-330,"elapsed":463,"user":{"displayName":"Tanishtha Chauhan","userId":"02571064042440070499"}}},"outputs":[],"source":["# Load Libraries - Make sure to run this cell!\n","\n","import pandas as pd\n","\n","import numpy as np\n","\n","import re\n","\n","from collections import Counter\n","\n","from sklearn import feature_extraction, tree, model_selection, metrics\n","\n","from yellowbrick.classifier import ClassificationReport\n","\n","from yellowbrick.classifier import ConfusionMatrix\n","\n","import matplotlib.pyplot as plt\n","\n","import matplotlib\n","\n","import io\n","\n","%matplotlib inline"]},{"cell_type":"code","source":["df_final = pd.read_csv('dga_features_final_df.csv')\n","\n","#If you didn't get a working dataset, uncomment this line\n","\n","#df_final = pd.read_csv('our_data_dga_features_final_df.csv')\n","\n","\n","\n","print(df_final.isDGA.value_counts())\n","\n","df_final.head()\n","\n","# Load dictionary of common english words from part 1\n","\n","from six.moves import cPickle as pickle\n","\n","with open('d_common_en_words' + '.pickle', 'rb') as f:\n","\n","        d = pickle.load(f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"BrTbomu-HsUd","executionInfo":{"status":"error","timestamp":1733994731006,"user_tz":-330,"elapsed":441,"user":{"displayName":"Tanishtha Chauhan","userId":"02571064042440070499"}},"outputId":"8ae87fc1-4e79-40f3-defc-4f96c0d3337f"},"execution_count":3,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'dga_features_final_df.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-96dee33c8507>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dga_features_final_df.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#If you didn't get a working dataset, uncomment this line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#df_final = pd.read_csv('our_data_dga_features_final_df.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dga_features_final_df.csv'"]}]},{"cell_type":"code","source":["target = df_final['isDGA']\n","\n","feature_matrix = df_final.drop(['isDGA'], axis=1)\n","\n","print('Final features', feature_matrix.columns)\n","\n","\n","\n","feature_matrix.head()"],"metadata":{"id":"catp1EzmHwBq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Simple Cross-Validation: Split the data set into training and test data\n","\n","feature_matrix_train, feature_matrix_test, target_train, target_test = model_selection.train_test_split(feature_matrix, target, test_size=0.25, random_state=33)\n","\n","feature_matrix_train.count()"],"metadata":{"id":"hktqdKcyHw0I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feature_matrix_test.count()"],"metadata":{"id":"iWNGPREcH0-F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_train.head()"],"metadata":{"id":"xg9t8GAPH5yI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_train.value_counts()"],"metadata":{"id":"RpZ-n1OIH80N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the decision tree based on the entropy criterion\n","\n","clf = tree.DecisionTreeClassifier()  # clf means classifier\n","\n","clf = clf.fit(feature_matrix_train, target_train)\n","\n","\n","\n","# Extract a row from the test data\n","\n","test_feature = feature_matrix_test[192:193]\n","\n","test_target = target_test[192:193]\n","\n","\n","\n","# Make the prediction\n","\n","pred = clf.predict(test_feature)\n","\n","print('Predicted class:', pred)\n","\n","print('Accurate prediction?', pred[0] == test_target)\n","\n","\n","\n","pred[0] == test_target"],"metadata":{"id":"KWMbn-3fIB_W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# For simplicity let's just copy the needed function in here again\n","\n","\n","\n","def H_entropy (x):\n","\n","    # Calculate Shannon Entropy\n","\n","    prob = [ float(x.count(c)) / len(x) for c in dict.fromkeys(list(x)) ]\n","\n","    H = - sum([ p * np.log2(p) for p in prob ])\n","\n","    return H\n","\n","\n","\n","def firstDigitIndex( s ):\n","\n","    for i, c in enumerate(s):\n","\n","        if c.isdigit():\n","\n","            return i + 1\n","\n","    return 0\n","\n","\n","\n","def vowel_consonant_ratio (x):\n","\n","    # Calculate vowel to consonant ratio\n","\n","    x = x.lower()\n","\n","    vowels_pattern = re.compile('([aeiou])')\n","\n","    consonants_pattern = re.compile('([b-df-hj-np-tv-z])')\n","\n","    vowels = re.findall(vowels_pattern, x)\n","\n","    consonants = re.findall(consonants_pattern, x)\n","\n","    try:\n","\n","        ratio = len(vowels) / len(consonants)\n","\n","    except: # catch zero devision exception\n","\n","        ratio = 0\n","\n","    return ratio\n","\n","\n","\n","# ngrams: Implementation according to Schiavoni 2014: \"Phoenix: DGA-based Botnet Tracking and Intelligence\"\n","\n","# http://s2lab.isg.rhul.ac.uk/papers/files/dimva2014.pdf\n","\n","\n","\n","def ngrams(word, n):\n","\n","    # Extract all ngrams and return a regular Python list\n","\n","    # Input word: can be a simple string or a list of strings\n","\n","    # Input n: Can be one integer or a list of integers\n","\n","    # if you want to extract multipe ngrams and have them all in one list\n","\n","\n","\n","    l_ngrams = []\n","\n","    if isinstance(word, list):\n","\n","        for w in word:\n","\n","            if isinstance(n, list):\n","\n","                for curr_n in n:\n","\n","                    ngrams = [w[i:i+curr_n] for i in range(0,len(w)-curr_n+1)]\n","\n","                    l_ngrams.extend(ngrams)\n","\n","            else:\n","\n","                ngrams = [w[i:i+n] for i in range(0,len(w)-n+1)]\n","\n","                l_ngrams.extend(ngrams)\n","\n","    else:\n","\n","        if isinstance(n, list):\n","\n","            for curr_n in n:\n","\n","                ngrams = [word[i:i+curr_n] for i in range(0,len(word)-curr_n+1)]\n","\n","                l_ngrams.extend(ngrams)\n","\n","        else:\n","\n","            ngrams = [word[i:i+n] for i in range(0,len(word)-n+1)]\n","\n","            l_ngrams.extend(ngrams)\n","\n","#     print(l_ngrams)\n","\n","    return l_ngrams\n","\n","\n","\n","def ngram_feature(domain, d, n):\n","\n","    # Input is your domain string or list of domain strings\n","\n","    # a dictionary object d that contains the count for most common english words\n","\n","    # finally you n either as int list or simple int defining the ngram length\n","\n","\n","\n","    # Core magic: Looks up domain ngrams in english dictionary ngrams and sums up the\n","\n","    # respective english dictionary counts for the respective domain ngram\n","\n","    # sum is normalized\n","\n","\n","\n","    l_ngrams = ngrams(domain, n)\n","\n","#     print(l_ngrams)\n","\n","    count_sum=0\n","\n","    for ngram in l_ngrams:\n","\n","        if d[ngram]:\n","\n","            count_sum+=d[ngram]\n","\n","    try:\n","\n","        feature = count_sum/(len(domain)-n+1)\n","\n","    except:\n","\n","        feature = 0\n","\n","    return feature\n","\n","\n","\n","def average_ngram_feature(l_ngram_feature):\n","\n","    # input is a list of calls to ngram_feature(domain, d, n)\n","\n","    # usually you would use various n values, like 1,2,3...\n","\n","    return sum(l_ngram_feature)/len(l_ngram_feature)\n","\n","In [17]:\n","\n","def is_dga(domain, clf, d):\n","\n","    # Function that takes new domain string, trained model 'clf' as input and\n","\n","    # dictionary d of most common english words\n","\n","    # returns prediction\n","\n","\n","\n","    domain_features = np.empty([1,6])\n","\n","    # order of features is ['length', 'digits', 'entropy', 'vowel-cons', firstDigitIndex, 'ngrams']\n","\n","    domain_features[0,0] = len(domain)\n","\n","    pattern = re.compile('([0-9])')\n","\n","    domain_features[0,1] = len(re.findall(pattern, domain))\n","\n","    domain_features[0,2] = H_entropy(domain)\n","\n","    domain_features[0,3] = vowel_consonant_ratio(domain)\n","\n","    domain_features[0,4] = firstDigitIndex(domain)\n","\n","    domain_features[0,5] = average_ngram_feature([ngram_feature(domain, d, 1),\n","\n","                                                  ngram_feature(domain, d, 2),\n","\n","                                                  ngram_feature(domain, d, 3)])\n","\n","    pred = clf.predict(domain_features)\n","\n","    return pred[0]\n","\n","\n","\n","\n","\n","print('Predictions of domain %s is [0 means legit and 1 dga]: ' %('spardeingeld'), is_dga('spardeingeld', clf, d))\n","\n","print('Predictions of domain %s is [0 means legit and 1 dga]: ' %('google'), is_dga('google', clf, d))\n","\n","print('Predictions of domain %s is [0 means legit and 1 dga]: ' %('1vxznov16031kjxneqjk1rtofi6'), is_dga('1vxznov16031kjxneqjk1rtofi6', clf, d))\n","\n","print('Predictions of domain %s is [0 means legit and 1 dga]: ' %('lthmqglxwmrwex'), is_dga('lthmqglxwmrwex', clf, d))\n","\n","\n","\n","is_dga('brandeis.edu', clf, d)"],"metadata":{"id":"1cHtamn-IFVk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fair approach: make prediction on test data portion\n","\n","target_pred = clf.predict(feature_matrix_test)\n","\n","print(metrics.accuracy_score(target_test, target_pred))\n","\n","print('Confusion Matrix\\n', metrics.confusion_matrix(target_test, target_pred))"],"metadata":{"id":"ZMqm3dkLIMPS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Classification Report...neat summary\n","\n","print(metrics.classification_report(target_test, target_pred, target_names=['legit', 'dga']))\n","\n","# short-cut\n","\n","clf.score(feature_matrix_test, target_test)\n","\n","viz = ConfusionMatrix(clf)\n","\n","viz.fit(feature_matrix_train, target_train)\n","\n","viz.score(feature_matrix_test, target_test)\n","\n","viz.show()\n","\n","viz = ClassificationReport(clf)\n","\n","viz.fit(feature_matrix_train, target_train)\n","\n","viz.score(feature_matrix_test, target_test)\n","\n","viz.poof()"],"metadata":{"id":"xhlg7TCkIPv_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cvKFold = model_selection.KFold(n_splits=3, shuffle=True, random_state=33)\n","\n","cvKFold.get_n_splits(feature_matrix)"],"metadata":{"id":"F11dd1iBIVVC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scores = model_selection.cross_val_score(clf, feature_matrix, target, cv=cvKFold)\n","\n","print(scores)\n","\n","# Get avergage score +- Standard Error (https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.sem.html)\n","\n","from scipy.stats import sem\n","\n","def mean_score( scores ):\n","\n","    return \"Mean score: {0:.3f} (+/- {1:.3f})\".format( np.mean(scores), sem( scores ))\n","\n","print( mean_score( scores))"],"metadata":{"id":"i-lNl_5uIWSQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.core.display import Image\n","\n","import pydotplus as pydot\n","\n","\n","\n","\n","\n","dot_data = io.StringIO()\n","\n","tree.export_graphviz(clf, out_file=dot_data,\n","\n","                     feature_names=['length', 'digits', 'entropy', 'vowel-cons', 'firstDigitIndex','ngrams'],\n","\n","                    filled=True, rounded=True,\n","\n","                    special_characters=True)\n","\n","\n","\n","graph = pydot.graph_from_dot_data(dot_data.getvalue())\n","\n","Image(graph.create_png())"],"metadata":{"id":"a9xi5tE9IaDx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn import svm\n","\n","from sklearn.ensemble import RandomForestClassifier\n","\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","#Create the Random Forest Classifier\n","\n","random_forest_clf = RandomForestClassifier(n_estimators=10,\n","\n","                             max_depth=None,\n","\n","                             min_samples_split=2,\n","\n","                             random_state=0)\n","\n","\n","\n","random_forest_clf = random_forest_clf.fit(feature_matrix_train, target_train)\n","\n","#Next, create the SVM classifier\n","\n","svm_classifier = svm.SVC()\n","\n","svm_classifier = svm_classifier.fit(feature_matrix_train, target_train)\n","\n","#Finally the knn\n","\n","knn_clf = KNeighborsClassifier()\n","\n","knn_clf = knn_clf.fit(feature_matrix_train, target_train)"],"metadata":{"id":"rl8-cvliIdmM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import lime.lime_tabular\n","\n","explainer = lime.lime_tabular.LimeTabularExplainer(feature_matrix_train,\n","\n","                                                   feature_names=['length', 'digits', 'entropy', 'vowel-cons', 'firstDigitIndex','ngrams'],\n","\n","                                                   class_names=['legit', 'isDGA'],\n","\n","                                                   discretize_continuous=False)\n","\n","exp = explainer.explain_instance(feature_matrix_test.iloc[9],\n","\n","                                 random_forest_clf.predict_proba,\n","\n","                                 num_features=6)\n","\n","exp.show_in_notebook(show_table=True, show_all=True)\n","\n","feature_matrix_test.iloc[5]"],"metadata":{"id":"kHBXf1sMIhsR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install scikit-plot\n","\n","from sklearn.metrics import ConfusionMatrixDisplay\n","\n","\n","\n","viz = ConfusionMatrixDisplay.from_predictions(\n","\n","    target_test, clf.predict(feature_matrix_test),\n","\n","    display_labels=['legit', 'dga'], cmap=plt.cm.Blues\n","\n",")\n","\n","viz.plot()\n","\n","viz.show()"],"metadata":{"id":"JXop_M2LImSf"},"execution_count":null,"outputs":[]}]}